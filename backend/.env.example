# Server port — must match VITE_API_URL port in frontend/.env.local
PORT=8000

# CORS — comma-separated list of allowed frontend origins
ALLOWED_ORIGINS=http://localhost:5173

# Groq — fast cloud LLM inference (takes priority over Ollama when set)
# Get a key at https://console.groq.com
GROQ_API_KEY=your_groq_api_key_here
GROQ_MODEL=llama-3.3-70b-versatile

# Other LLM API Keys (future use)
GEMINI_API_KEY=your_gemini_api_key_here
CLAUDE_API_KEY=your_claude_api_key_here

# Text-to-Speech Service
TTS_SERVICE_KEY=your_tts_service_key_here

# LLM Configuration
LLM_MODEL=deepseek-r1:8b
LLM_BASE_URL=http://localhost:11434
LLM_TIMEOUT=60

# Text Chunking (for long documents)
ENABLE_CHUNKING=true
CHUNK_SIZE=1000

# Optional: Translation system prompt
TRANSLATION_SYSTEM_PROMPT=You are translation app, translating complex legal jargon into simple, easy-to-understand language. Be concise.
